{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Machine Learning', \n",
    "    'Model training',\n",
    "    'Supervised learning', \n",
    "    'Unsupervised learning', \n",
    "    'Reinforcement learning', \n",
    "    'Computer Hardware Engineering', \n",
    "    'Computer Security', \n",
    "    'Computer architecture', \n",
    "    'Operating System', \n",
    "    'Parallel computing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Machine', 'Learning'],\n",
       " ['Model', 'training'],\n",
       " ['Supervised', 'learning'],\n",
       " ['Unsupervised', 'learning'],\n",
       " ['Reinforcement', 'learning'],\n",
       " ['Computer', 'Hardware', 'Engineering'],\n",
       " ['Computer', 'Security'],\n",
       " ['Computer', 'architecture'],\n",
       " ['Operating', 'System'],\n",
       " ['Parallel', 'computing']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tokens from the list of sentences \n",
    "token_sentences = [sen.split() for sen in sentences]\n",
    "token_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of unique tokens \n",
    "all_tokens = set([word for sentence in token_sentences for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer',\n",
       " 'Engineering',\n",
       " 'Hardware',\n",
       " 'Learning',\n",
       " 'Machine',\n",
       " 'Model',\n",
       " 'Operating',\n",
       " 'Parallel',\n",
       " 'Reinforcement',\n",
       " 'Security',\n",
       " 'Supervised',\n",
       " 'System',\n",
       " 'Unsupervised',\n",
       " 'architecture',\n",
       " 'computing',\n",
       " 'learning',\n",
       " 'training']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To increase the readability, let's sort the corpus of our text \n",
    "all_tokens = sorted(all_tokens)\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer encoding using Sklearn \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(all_tokens)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([5, 4]),\n",
       " array([ 6, 17]),\n",
       " array([11, 16]),\n",
       " array([13, 16]),\n",
       " array([ 9, 16]),\n",
       " array([1, 3, 2]),\n",
       " array([ 1, 10]),\n",
       " array([ 1, 14]),\n",
       " array([ 7, 12]),\n",
       " array([ 8, 15])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_sentences = []\n",
    "for sentence in sentences: \n",
    "    encoded_sentences.append(label_encoder.transform(sentence.split(' ')) + 1)\n",
    "    \n",
    "encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5,  4,  0],\n",
       "       [ 6, 17,  0],\n",
       "       [11, 16,  0],\n",
       "       [13, 16,  0],\n",
       "       [ 9, 16,  0],\n",
       "       [ 1,  3,  2],\n",
       "       [ 1, 10,  0],\n",
       "       [ 1, 14,  0],\n",
       "       [ 7, 12,  0],\n",
       "       [ 8, 15,  0]], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Since the sentences size is different, we need to add padding. \n",
    "max_length = 3 # No more than three words per sentence \n",
    "#padding = post since we need to fill the zeros at the end\n",
    "padded_enc_sentences = pad_sequences(encoded_sentences, maxlen=max_length, padding='post')\n",
    "padded_enc_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Embedding Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(input_dim=len(all_tokens), output_dim=2, input_length=3)\n",
    "model.add(embedding_layer)\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning\n",
      "(3,)\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/mohammedalhamid/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-0.04924556,  0.04319364],\n",
       "        [ 0.03612458, -0.0233996 ],\n",
       "        [-0.00706597, -0.01268903]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentences[0])\n",
    "print(padded_enc_sentences[0].shape)\n",
    "model.predict(padded_enc_sentences[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
