{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Machine Learning', \n",
    "    'Model training',\n",
    "    'Supervised learning', \n",
    "    'Unsupervised learning', \n",
    "    'Reinforcement learning', \n",
    "    'Computer Hardware Engineering', \n",
    "    'Computer Security', \n",
    "    'Computer architecture', \n",
    "    'Operating System', \n",
    "    'Parallel computing'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Machine', 'Learning'],\n",
       " ['Model', 'training'],\n",
       " ['Supervised', 'learning'],\n",
       " ['Unsupervised', 'learning'],\n",
       " ['Reinforcement', 'learning'],\n",
       " ['Computer', 'Hardware', 'Engineering'],\n",
       " ['Computer', 'Security'],\n",
       " ['Computer', 'architecture'],\n",
       " ['Operating', 'System'],\n",
       " ['Parallel', 'computing']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the tokens from the list of sentences \n",
    "token_sentences = [sen.split() for sen in sentences]\n",
    "token_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a set of unique tokens \n",
    "all_tokens = set([word for sentence in token_sentences for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Computer',\n",
       " 'Engineering',\n",
       " 'Hardware',\n",
       " 'Learning',\n",
       " 'Machine',\n",
       " 'Model',\n",
       " 'Operating',\n",
       " 'Parallel',\n",
       " 'Reinforcement',\n",
       " 'Security',\n",
       " 'Supervised',\n",
       " 'System',\n",
       " 'Unsupervised',\n",
       " 'architecture',\n",
       " 'computing',\n",
       " 'learning',\n",
       " 'training']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To increase the readability, let's sort the corpus of our text \n",
    "all_tokens = sorted(all_tokens)\n",
    "all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer encoding using Sklearn \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(all_tokens)\n",
    "integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = []\n",
    "for sentence in sentences: \n",
    "    encoded_sentences.append(label_encoder.transform(sentence.split(' ')) + 1)\n",
    "    \n",
    "encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# Since the sentences size is different, we need to add padding. \n",
    "max_length = 3 # No more than three words per sentence \n",
    "#padding = post since we need to fill the zeros at the end\n",
    "padded_enc_sentences = pad_sequences(encoded_sentences, maxlen=max_length, padding='post')\n",
    "padded_enc_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an Embedding Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(input_dim=len(all_tokens), output_dim=2, input_length=3)\n",
    "model.add(embedding_layer)\n",
    "model.compile('adam', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences[0])\n",
    "print(padded_enc_sentences[0].shape)\n",
    "model.predict(padded_enc_sentences[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
